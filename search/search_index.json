{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p><code>open-dapro</code> is the data orchestration and pipelining tool for the German Energy System built with Dagster, dbt, PostGIS, and GeoServer. Its purpose is the collection and combination of data from different sources. The data pipelines can be scheduled regularly to keep the database up to date.</p> <p>Use <code>open-dapro</code> if you want to</p> <ul> <li>Have a local database of houses, electricity producers, ... on your server which updates automatically. </li> <li>Extend existing pipelines with the datasets you need.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<ol> <li>Clone the repository git.fortiss.org/ASCI-public/energy-dagster and open it in a terminal.</li> <li>Make sure you have docker and docker-compose installed by running  <pre><code>docker --version\ndocker-compose --version\n</code></pre></li> <li>Run <code>docker-compose up</code> and go to localhost:3000 to see the dagster UI. A documentation of the dagster UI can be found here.</li> <li>Start exploring the data pipelines </li> </ol> <p>For an alternative setup you can also follow the instructions in the Setup for development.</p>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#modules","title":"Modules","text":"<p>The codebase of <code>open-dapro</code> builds upon several open-source frameworks: </p> <ul> <li>Dagster is a data pipelining tool. You can use it to define workflows based on python scripts and schedule their execution.</li> <li>dbt is a data transformation and testing tool. You can build modular sql-based data transformations and build data unit tests.</li> <li>PostGIS is an extension of PostgreSQL to handle geodata. It is used to save raw and transformed data sets.</li> <li>GeoServer is a tool to host OGC-conform APIs based on a Postgis database. </li> </ul> <p>All of those tools have their own documentation pages. Make sure that you have a rough idea of their functionalities by checking their documentation pages.</p> <pre><code>flowchart LR\n    subgraph Dagster\n    id1.1(\"Dataset 1:\n    csv File\")--&gt;id2[(Postgis Database)]\n    id1.2(\"Dataset 2:\n    images\")--&gt;|Extract Information|id1.3(Tabular Data)\n    id1.3--&gt;id2\n    id1.5(Dataset 3, ...)--&gt;id2\n    subgraph Database\n    id2--&gt;|Transformation with dbt|id2\n    end\n    id2--&gt;id3[\"Vizualization and Analysis\n    Using Python Scripts\"]\n    end\n    subgraph GeoServer\n    id2--&gt;id4(API: Geojson, WFS, WMS)\n    end</code></pre>"},{"location":"datasets/","title":"Datasets","text":"<p><code>open-dapro</code> contains pipelines for the following data sources:</p> Dataset Description License <code>Open Street Maps</code> Building footprints and usage type based on geofabrik OpenStreetMaps and Geofrabrik Data under Open Data Commons Open Database License (ODbL) <code>Marktstammdatenregister</code> All electricity producers in Germany, based on open-mastr Marktstammdatenregister - \u00a9 Bundesnetzagentur f\u00fcr Elektrizit\u00e4t, Gas, Telekommunikation, Post und Eisenbahnen DL-DE-BY-2.0 <code>LOD2 Bavaria</code> LOD2 data for the German state of Bavaria LOD2 Data from  Landesamt f\u00fcr Digitalisierung, Breitband und Vermessung under CC BY 4.0 <code>Ladesauelenregister</code> Location and power capacity of electric vehicle charging stations Lades\u00e4ulenregister - \u00a9 Bundesnetzagentur.de CC BY 4.0 <code>Administrative Areas</code> Boundaries of municipalities and districts Verwaltungsgebiete from Bundesamt f\u00fcr Kartographie und Geod\u00e4sie licensed under Datenlizenz Deutschland - Namensnennung - Version 2.0 <code>ALKIS area usage</code> Categorization of area usage in bavaria: Settlement, Traffic, Vegetation, Water Bodies ALKIS\u00ae-Tats\u00e4chliche Nutzung from  Landesamt f\u00fcr Digitalisierung, Breitband und Vermessung under CC BY 4.0 <code>Destatis Gemeindeverzeichnis</code> Number of inhabitants for municipalities Gemeindeverzeichnis \u00a9 Statistisches Bundesamt (Destatis), License not found"},{"location":"development/","title":"Setup for development","text":""},{"location":"development/#installation","title":"Installation","text":"<ol> <li>Clone the repository github.com/OpenEnergyPlatform/open-dapro and open it.</li> <li> <p>Install your Dagster code location as a Python package. By using the -e (editable) flag, pip will install your Python package in \"editable mode\" so that as you develop, local code changes will automatically apply.</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> </li> <li> <p>Next, make sure you have docker and docker-compose installed. You can check this by running:</p> <pre><code>docker-compose --version\n</code></pre> </li> <li> <p>You now need to rename the <code>.env.template</code> file to <code>.env</code> and change your credentials if needed. The <code>.env</code> file will not be uploaded to git. Note that these credentials have to match the database created with the <code>development/docker-compose.yml</code> file. </p> </li> <li> <p>To initialize the database and to create the docker container, run:</p> <p><pre><code>python development/initialize.py\n</code></pre> Check if the database is running on the server and port specified in the <code>.env</code> file. </p> </li> <li> <p>Start the Dagster UI web server:</p> <pre><code>dagster dev\n</code></pre> <p>If the environment variables were loaded successfully, you should see the following line:</p> <pre><code>dagster - INFO - Loaded environment variables from .env file: pwd,uid,server,db,port,schema, MASTR_DOWNLOAD_DATE\n</code></pre> </li> <li> <p>Open 127.0.0.1:3000 with your browser to see the project. You can start writing your own assets in <code>energy_dagster/assets.py</code>. The assets are automatically loaded into the Dagster code location as you define them.</p> </li> </ol>"},{"location":"development/#tools-we-use","title":"Tools we use","text":""},{"location":"development/#pre-commit-hooks","title":"pre-commit hooks","text":"<p>In this project, we use pre-commit hooks to lint the code before committing. The hooks are defined in the <code>.pre-commit-config.yaml</code> file. To install the hooks, run the following command:</p> <pre><code>pre-commit install\n</code></pre> <p>This will install the hooks in your local repository. They will be executed before every commit and check for linting errors using the sqlfluff and black packages.</p>"},{"location":"development/#dbt-osmosis","title":"dbt osmosis","text":"<p>You can use <code>dbt-osmosis</code> for creating, updating, and deleting dbt property files. This can be done using the following command:</p> <pre><code>dbt-osmosis yaml refactor .\\models\\marts\\\n</code></pre>"},{"location":"development/#dbt-style-guide","title":"dbt Style Guide","text":"<p>This style guide is a shortened version of the dbt-labs style guide.</p>"},{"location":"development/#model-organization","title":"Model Organization","text":"<p>Our models (typically) fit into two main categories:</p> Category Description Staging Contains models which clean and standardize data Marts Contains models which combine or heavily transform data <p>Things to note: - There are different types of models that typically exist in each of the above categories. See Model Layers for more information. </p> <ul> <li>Read How we structure our dbt projects for an example and more details around organization.</li> </ul>"},{"location":"development/#model-layers","title":"Model Layers","text":"<ul> <li>Only models in <code>staging</code> should select from sources</li> <li>Models not within the <code>staging</code> folder should select from refs.</li> <li> <p>The following are the DAG stages that we tend to utilize:</p> dag_stage Typically found in description seed_ /seeds <li> Indicates a data set created from <code>dbt seed</code>. stg_ /models/staging <li> Indicates a data set that is being cleaned and standardized. </li><li> In absence of a base_ layer, it representthe 1:1 relationship between the source and first layer of models. li&gt; int_ /models/marts <li> Indicates a logical step towards creating a final data set. </li><li>Typically used for:</li><ul><li>Breaking ua very large fct_ or dim_ model into smaller pieces to reduce complexity</li><li>Creating a reusable data set to reference in multiple downstream fctand dim_ models</li></ul> dim_ /models/marts <li> Flags data which is used to describe an entity. </li><li> Indicates a final data which is robust, versatile, anready for consumption. </li> base_ /models/staging <li> Indicates cleaning and standardization on a data set before joining to other data sets in <code>stg_</code> models.<li> Typically used when multiple sources are rarely used independently.  Example: Location data in our org is seldom used partially, so we want to create one cleaned data set which puts it all together.  Step 1: Models to clean and standardize each data set:<ul><li>base_location__addresses.sql</li><li>base_location__countries.sql</li><li>base_location__states.sql</li></ul>Step 2: A model to join all location data as one entity for use in downstream modeling:<ul><li>stg_location__locations.sql</li></ul>"},{"location":"development/#model-file-naming-and-coding","title":"Model File Naming and Coding","text":"<ul> <li> <p>All objects should be plural.   Example: <code>stg_stripe__invoices.sql</code> vs. <code>stg_stripe__invoice.sql</code></p> </li> <li> <p>All objects should have a prefix to indicate their DAG stage in the flow.   See Model Layers for more information.</p> </li> <li> <p>All models should use the naming convention <code>&lt;type/dag_stage&gt;_&lt;source/topic&gt;__&lt;additional_context&gt;</code>. See this article for more information.</p> </li> <li>For models in the marts folder <code>__&lt;additional_context&gt;</code> is optional. </li> <li> <p>Models in the staging folder should use the source's name as the <code>&lt;source/topic&gt;</code> and the entity name as the <code>additional_context</code>.</p> <p>Examples: - seed_snowflake_spend.csv - base_stripe__invoices.sql - stg_stripe__customers.sql - stg_salesforce__customers.sql - int_customers__unioned.sql - fct_orders.sql</p> </li> <li> <p>Schema, table and column names should be in <code>snake_case</code>.</p> </li> <li> <p>Limit use of abbreviations that are related to domain knowledge. An onboarding   employee will understand <code>current_order_status</code> better than <code>current_os</code>.</p> </li> <li> <p>Each model should have a primary key that can identify the unique row, and should be named <code>&lt;object&gt;_id</code>, e.g. <code>account_id</code> \u2013 this makes it easier to know what <code>id</code> is being referenced in downstream joined models.</p> </li> <li> <p>For <code>base</code> or <code>staging</code> models, columns should be ordered in categories, where identifiers are first and date/time fields are at the end.   Example:   <pre><code>transformed as (\n    select\n        -- ids\n        order_id,\n        customer_id,\n\n        -- dimensions\n        order_status,\n        is_shipped,\n\n        -- measures\n        order_total,\n\n        -- date/times\n        created_at,\n        updated_at,\n\n        -- metadata\n        _sdc_batched_at\n    from source\n)\n</code></pre></p> </li> <li> <p>Date/time columns should be named according to these conventions:</p> </li> <li> <p>Timestamps: <code>&lt;event&gt;_at</code>     Format: UTC     Example: <code>created_at</code></p> </li> <li> <p>Dates: <code>&lt;event&gt;_date</code>     Format: Date     Example: <code>created_date</code></p> </li> <li> <p>Booleans should be prefixed with <code>is_</code> or <code>has_</code>.   Example: <code>is_active_customer</code> and <code>has_admin_access</code></p> </li> <li> <p>Avoid using reserved words (such as these for Snowflake) as column names.</p> </li> <li> <p>Consistency is key! Use the same field names across models where possible. Example: a key to the <code>customers</code> table should be named <code>customer_id</code> rather than <code>user_id</code>.</p> </li> </ul>"},{"location":"development/#model-configurations","title":"Model Configurations","text":"<ul> <li>Model configurations at the folder level should be considered (and if applicable, applied) first.</li> <li>More specific configurations should be applied at the model level using one of these methods.</li> <li>Models within the <code>marts</code> folder should be materialized as <code>table</code> or <code>incremental</code>.</li> <li>By default, <code>marts</code> should be materialized as <code>table</code> within <code>dbt_project.yml</code>.</li> <li>If switching to <code>incremental</code>, this should be specified in the model's configuration.</li> </ul>"},{"location":"development/#testing","title":"Testing","text":"<ul> <li>At a minimum, <code>unique</code> and <code>not_null</code> tests should be applied to the expected primary key of each model.</li> </ul>"},{"location":"development/#ctes","title":"CTEs","text":"<p>For more information about why we use so many CTEs, check out this glossary entry.</p> <ul> <li> <p>Where performance permits, CTEs should perform a single, logical unit of work.</p> </li> <li> <p>CTE names should be as verbose as needed to convey what they do.</p> </li> <li> <p>CTEs with confusing or noteable logic should be commented with SQL comments as you would with any complex functions, and should be located above the CTE.</p> </li> <li> <p>CTEs that are duplicated across models should be pulled out and created as their own models.</p> </li> <li> <p>CTEs fall in to two main categories:</p> Term Definition Import Used to bring data into a model. These are kept relatively simple and refrain from complex operations such as joins and column transformations. Logical Used to perform a logical step with the data that is brought into the model toward the end result. </li> <li> <p>All <code>{{ ref() }}</code> or <code>{{ source() }}</code> statements should be placed within import CTEs so that dependent model references are easily seen and located.</p> </li> <li> <p>Where applicable, opt for filtering within import CTEs over filtering within logical CTEs. This allows a developer to easily see which data contributes to the end result.</p> </li> <li> <p>SQL should end with a simple select statement. All other logic should be contained within CTEs to make stepping through logic easier while troubleshooting.   Example: <code>select * from final</code></p> </li> <li> <p>SQL and CTEs within a model should follow this structure:</p> </li> <li><code>with</code> statement</li> <li>Import CTEs</li> <li>Logical CTEs</li> <li>Simple select statement</li> </ul>"},{"location":"development/#example-sql-with-ctes","title":"Example SQL with CTEs","text":"<pre><code> -- Jaffle shop went international!\nwith\n\n-- Import CTEs\nregions as (\n    select * from {{ ref('stg_jaffle_shop__regions') }}\n),\n\nnations as (\n    select * from {{ ref('stg_jaffle_shop__nations') }}\n),\n\nsuppliers as (\n    select * from {{ ref('stg_jaffle_shop__suppliers') }}\n),\n\n-- Logical CTEs\nlocations as (\n    select\n        {{ dbt_utils.generate_surrogate_key([\n            'regions.region_id',            \n            'nations.nation_id'\n        ]) }} as location_sk,\n        regions.region_id,\n        regions.region,\n        regions.region_comment,\n        nations.nation_id,\n        nations.nation,\n        nations.nation_comment\n    from regions\n    left join nations\n        on regions.region_id = nations.region_id\n),\n\nfinal as (\n    select\n        suppliers.supplier_id,\n        suppliers.location_id,\n        locations.region_id,\n        locations.nation_id,\n        suppliers.supplier_name,\n        suppliers.supplier_address,\n        suppliers.phone_number,\n        locations.region,\n        locations.region_comment,\n        locations.nation,\n        locations.nation_comment,\n        suppliers.account_balance\n    from suppliers\n    inner join locations\n        on suppliers.location_id = locations.location_sk\n)\n\n-- Simple select statement\nselect * from final\n</code></pre>"},{"location":"development/#sql-style-guide","title":"SQL style guide","text":"<ul> <li>DO NOT OPTIMIZE FOR FEWER LINES OF CODE. </li> </ul> <p>New lines are cheap, brain time is expensive; new lines should be used within reason to produce code that is easily read.</p> <ul> <li> <p>When dealing with long <code>when</code> or <code>where</code> clauses, predicates should be on a new   line and indented.   Example:   <pre><code>where \n    user_id is not null\n    and status = 'pending'\n    and location = 'hq'\n</code></pre></p> </li> <li> <p>Lines of SQL should be no longer than 80 characters and new lines should be used to ensure this.   Example:   <pre><code>sum(\n    case\n        when order_status = 'complete'\n            then order_total \n    end\n) as monthly_total,\n\n\n\n{{ get_windowed_values(\n      strategy='sum',\n      partition='order_id',\n      order_by='created_at',\n      column_list=[\n          'final_cost'\n      ]\n) }} as total_final_cost\n</code></pre></p> </li> <li> <p>Use all lowercase unless a specific scenario needs you to do otherwise. This means that keywords, field names, function names, and file names   should all be lowercased.</p> </li> <li> <p>The <code>as</code> keyword should be used when aliasing a field or table</p> </li> <li> <p>Fields should be stated before aggregates / window functions</p> </li> <li> <p>Aggregations should be executed as early as possible before joining to another table.</p> </li> <li> <p>Ordering and grouping by a number (eg. group by 1, 2) is preferred over listing the column names (see this rant for why). Note that if you are grouping by more than a few columns, it may be worth revisiting your model design. If you really need to, the dbt_utils.group_by function may come in handy.</p> </li> <li> <p>Prefer <code>union all</code> to <code>union</code> *</p> </li> <li> <p>Avoid table aliases in join conditions (especially initialisms) \u2013 it's harder to understand what the table called \"c\" is compared to \"customers\".</p> </li> <li> <p>If joining two or more tables, always prefix your column names with the table alias. If only selecting from one table, prefixes are not needed.</p> </li> <li> <p>Be explicit about your join (i.e. write <code>inner join</code> instead of <code>join</code>). <code>left joins</code> are the most common, <code>right joins</code> often indicate that you should change which table you select <code>from</code> and which one you <code>join</code> to.</p> </li> <li> <p>Avoid the <code>using</code> clause in joins, preferring instead to explicitly list the CTEs and associated join keys with an <code>on</code> clause.</p> </li> <li> <p>Joins should list the left table first (i.e., the table you're joining data to)   Example:   <pre><code>select\n    trips.*,\n    drivers.rating as driver_rating,\n    riders.rating as rider_rating\nfrom trips\nleft join users as drivers\n   on trips.driver_id = drivers.user_id\nleft join users as riders\n    on trips.rider_id = riders.user_id\n</code></pre></p> </li> </ul>"},{"location":"development/#example-sql","title":"Example SQL","text":"<pre><code>with\n\nmy_data as (\n    select * from {{ ref('my_data') }}\n    where not is_deleted\n),\n\nsome_cte as (\n    select * from {{ ref('some_cte') }}\n),\n\nsome_cte_agg as (\n    select\n        id,\n        sum(field_4) as total_field_4,\n        max(field_5) as max_field_5\n    from some_cte\n    group by 1\n),\n\nfinal as (\n    select [distinct]\n        my_data.field_1,\n        my_data.field_2,\n        my_data.field_3,\n\n        -- use line breaks to visually separate calculations into blocks\n        case\n            when my_data.cancellation_date is null\n                and my_data.expiration_date is not null\n                then expiration_data\n            when my_data.cancellation_date is null\n                then my_data.start_date + 7\n            else my_data.cancellation_date\n        end as cancellation_date,\n\n        some_cte_agg.total_field_4,\n        some_cte_agg.max_field_5\n    from my_data\n    left join some_cte_agg  \n        on my_data.id = some_cte_agg.id\n    where \n        my_data.field_1 = 'abc'\n        and (\n            my_data.field_2 = 'def'\n            or my_data.field_2 = 'ghi'\n        )\n    qualify row_number() over(\n        partition by my_data.field_1\n        order by my_data.start_date desc\n    ) = 1\n)\n\nselect * from final\n</code></pre>"},{"location":"development/#yaml-and-markdown-style-guide","title":"YAML and Markdown style guide","text":"<ul> <li> <p>Every subdirectory contains their own <code>.yml</code> file(s) which contain configurations for the models within the subdirectory.</p> </li> <li> <p>YAML and markdown files should be prefixed with an underscore ( <code>_</code> ) to keep it at the top of the subdirectory.</p> </li> <li> <p>YAML and markdown files should be named with the convention <code>_&lt;description&gt;__&lt;config&gt;</code>.  </p> </li> </ul> <p>Examples: <code>_jaffle_shop__sources.yml</code>, <code>_jaffle_shop__docs.md</code> </p> <ul> <li><code>description</code> is typically the folder of models you're setting configurations for.     Examples: <code>core</code>, <code>staging</code>, <code>intermediate</code></li> <li><code>config</code> is the top-level resource you are configuring.     Examples: <code>docs</code>, <code>models</code>, <code>sources</code></li> <li> <p>Indents should use two spaces.</p> </li> <li> <p>List items should be indented.</p> </li> <li> <p>Use a new line to separate list items that are dictionaries, where appropriate.</p> </li> <li> <p>Lines of YAML should be no longer than 80 characters.</p> </li> <li> <p>Items listed in a single .yml or .md file should be sorted alphabetically for ease of finding in larger files.</p> </li> <li> <p>Each top-level configuration should use a separate <code>.yml</code> file (i.e, sources, models)   Example:   <pre><code>models\n\u251c\u2500\u2500 marts\n\u2514\u2500\u2500 staging\n    \u2514\u2500\u2500 jaffle_shop\n        \u251c\u2500\u2500 _jaffle_shop__docs.md\n\n        \u251c\u2500\u2500 _jaffle_shop__models.yml\n        \u251c\u2500\u2500 _jaffle_shop__sources.yml\n        \u251c\u2500\u2500 stg_jaffle_shop__customers.sql\n        \u251c\u2500\u2500 stg_jaffle_shop__orders.sql\n        \u2514\u2500\u2500 stg_jaffle_shop__payments.sql\n</code></pre></p> </li> <li> <p><code>dbt_project.yml</code> configurations should be prefixed with <code>+</code> to avoid namespace collision with directories.</p> </li> </ul> <p>Example:   <pre><code>models:\n  my_project:\n    marts:\n      +materialized: table\n</code></pre></p>"},{"location":"development/#example-yaml","title":"Example YAML","text":"<p><code>_jaffle_shop__models.yml</code>:</p> <pre><code>version: 2\n\nmodels:\n\n  - name: base_jaffle_shop__nations\n\n    description: This model cleans the raw nations data\n    columns:\n      - name: nation_id\n        tests:\n          - unique\n          - not_null   \n\n  - name: base_jaffle_shop__regions\n    description: &gt;\n      This model cleans the raw regions data before being joined with nations\n      data to create one cleaned locations table for use in marts.\n    columns:\n      - name: region_id\n        tests:\n          - unique\n          - not_null\n\n  - name: stg_jaffle_shop__locations\n\n    description: \"{{ doc('jaffle_shop_location_details') }}\"\n\n    columns:\n      - name: location_sk\n        tests:\n          - unique\n          - not_null\n</code></pre> <p>#### Example Markdown   <code>_jaffle_shop__docs.md</code>:</p> <p>```markdown</p> <pre><code>  Although most of our data sets have statuses attached, you may find some\n  that are enumerated. The following table can help you identify these statuses.\n  | Status | Description                                                                 |\n  |--------|---------------|\n  | 1      | ordered       |\n  | 2      | shipped       |\n  | 3      | pending       |\n  | 4      | order_pending |\n\n\n{% enddocs %}\n\n{% docs statuses %}\n\n  Statuses can be found in many of our raw data sets. The following lists\n  statuses and their descriptions:\n  | Status        | Description                                                                 |\n  |---------------|-----------------------------------------------------------------------------|\n  | ordered       | A customer has paid at checkout.                                            |\n  | shipped       | An order has a tracking number attached.                                    |\n  | pending       | An order has been paid, but doesn't have a tracking number.                 |\n  | order_pending | A customer has not yet paid at checkout, but has items in their cart. |\n\n{% enddocs %}\n</code></pre> <p>```</p>"},{"location":"development/#jinja-style-guide","title":"Jinja style guide","text":"<ul> <li> <p>Jinja delimiters should have spaces inside of the delimiter between the brackets and your code.   Example: <code>{{ this }}</code> instead of <code>{{this}}</code></p> </li> <li> <p>Use whitespace control to make compiled SQL more readable.</p> </li> <li> <p>An effort should be made for a good balance in readability for both templated  and compiled code. However, opt for code readability over compiled SQL readability when needed.</p> </li> <li> <p>A macro file should be named after the main macro it contains.</p> </li> <li> <p>A file with more than one macro should follow these conventions:</p> </li> <li>There is one macro which is the main focal point</li> <li>The file is named for the main macro or idea</li> <li> <p>All other macros within the file are only used for the purposes of the main      idea and not used by other macros outside of the file.</p> </li> <li> <p>Use new lines to visually indicate logical blocks of Jinja or to enhance readability.   Example: <pre><code>{%- set orig_cols = adapter.get_columns_in_relation(ref('fct_orders')) %}\n\n{%- set new_cols = dbt_utils.star(\n      from=ref('fct_order_items'),\n      except=orig_cols\n) %}\n\n-- original columns. {{ col }} is indented here, but choose what will satisfy\n-- your own balance for Jinja vs. SQL readability. \n{%- for col in orig_cols %}\n      {{ col }}\n{% endfor %}\n\n-- column difference\n{{ new_cols }}\n</code></pre></p> </li> <li> <p>Use new lines within Jinja delimiters and arrays if there are multiple arguments.   Example:   <pre><code>{%- dbt_utils.star(\n      from=ref('stg_jaffle_shop__orders'),\n      except=[\n          'order_id',\n          'ordered_at',\n          'status'\n      ],\n      prefix='order_'\n) %}\n</code></pre></p> </li> </ul>"},{"location":"development/#metrics-style-guide","title":"Metrics style guide","text":""},{"location":"development/#organizing-metrics","title":"Organizing Metrics","text":"<ul> <li>Metrics are categorized by entity (object grain that the metrics occurs), and filenames directly correspond to metrics.   Filenames are prefixed with <code>base__</code> only if they are pre-calculated inputs to derived metrics in other files.   <pre><code>\u251c\u2500\u2500 dbt_project.yml\n\u2514\u2500\u2500 models\n    \u251c\u2500\u2500 marts\n    \u251c\u2500\u2500 staging\n    \u2514\u2500\u2500 metrics\n        \u251c\u2500\u2500 projects\n        |   \u251c\u2500\u2500 active_projects.yml\n        \u251c\u2500\u2500 accounts\n        |   \u251c\u2500\u2500 active_cloud_accounts.yml\n        \u2514\u2500\u2500 users\n            \u251c\u2500\u2500 base__net_promoter_score.yml\n            \u2514\u2500\u2500 net_promoter_score.yml\n</code></pre></li> </ul>"},{"location":"development/#metrics-conventions","title":"Metrics Conventions","text":"<p>dbt Metrics fall into four broad categories: 1. Company metrics 2. Team KPIs 3. OKRs 4. Specific metrics related to a product area, business unit, or business function that is not necessarily a team KPI, but important to track nonetheless.</p> <p>Because of the wide socialization of these docs and downstream usage in the BI layer, consistency and clarity are very important. Below are the general standards and examples of how we format and implement metrics at dbt Labs: * Metrics names must begin with a letter, cannot contain whitespace, and should be all lowercase. * The minimum required properties must be present in the metric definition. * Tags and/or Meta properties should match the categories above and be used to organize metrics at the category or business function level. * Meta properties should be used to track metric definition ownership. * For up-to-date information on metrics, please see the metrics docs on defining a metric or the dbt-labs/metrics README</p>"},{"location":"development/#example-metrics-yaml","title":"Example Metrics YAML","text":"<pre><code>version: 2\n\nmetrics:\n  - name: base__total_nps_respondents_cloud\n    label: (Base) Total of NPS Respondents (Cloud)\n    model: ref('fct_customer_nps')\n    description: &gt;\n      'The count of users responding to NPS surveys in dbt Cloud.'\n    tags: ['Company Metric']\n\n    calculation_method: count\n    expression: unique_id\n\n    timestamp: created_at\n    time_grains: [day, month, quarter, year]\n\n    dimensions:\n      - feedback_source\n\n    filters:\n      - field: feedback_source\n        operator: '='\n        value: \"'dbt_cloud_nps'\"\n\n    meta:\n      metric_level: 'Company'\n      owner(s): 'Jane Doe'\n\n\n  - name: base__count_nps_promoters_cloud\n    label: (Base) Count of NPS Promoters (Cloud)\n    model: ref('fct_customer_nps')\n    description: &gt;\n      'The count of dbt Cloud respondents that fall into the promoters segment.'\n    tags: ['Company Metric']\n\n    calculation_method: count\n    expression: unique_id\n\n    timestamp: created_at\n    time_grains: [day, month, quarter, year]\n\n    filters:\n      - field: feedback_source\n        operator: '='\n        value: \"'dbt_cloud_nps'\"\n      - field: nps_category\n        operator: '='\n        value: \"'promoter'\"\n\n    meta:\n      metric_level: 'Company'\n      owner(s): 'Jane Doe'\n\n  - name: promoters_pct\n    label: Percent Promoters (Cloud)\n    description: 'The percent of dbt Cloud users in the promoters segment.'\n    tags: ['Company Metric']\n\n    calculation_method: derived\n    expression: \"{{metric('base__count_nps_promoters_cloud')}} / {{metric('base__total_nps_respondents_cloud')}}\" \n\n    timestamp: created_at\n    time_grains: [day, month, quarter, year]\n\n    meta:\n      metric_level: 'Company'\n      owner(s): 'Jane Doe'\n</code></pre>"}]}